{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008e690e-6886-4a04-b942-901554e4cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langgraph -q\n",
    "!pip install langchain -q\n",
    "!pip install ollama -q\n",
    "\n",
    "!pip install pymongo -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b960610-6986-44a0-8c68-d3a3c90b3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f19696-d39a-425e-97b4-d3da711b03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "database = client['LangChain_Intento4']\n",
    "collection = database['lenguajes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d134181-fdae-4a98-a0f7-0607ee51dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui debe llegar user_name y user_email\n",
    "# esto buscará el usuario según el email\n",
    "\n",
    "def function1(state): #buscar usuario\n",
    "    messages = state['messages']\n",
    "    agent_response = messages[-1]\n",
    "    documents = collection.find({'email': user_email})\n",
    "    user_agenda = []\n",
    "    for document in documents:\n",
    "        user_agenda.append(document)\n",
    "        state['messages'].append(user_agenda)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae4c7fb-b2a5-49dc-9b01-751132232688",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dia = \"15\"\n",
    "user_mes = \"mayo\"\n",
    "user_hora = \"14\"\n",
    "\n",
    "# aqui debe llegar user_dia, user_mes y user_hora\n",
    "\n",
    "def function2(state): #agendar cita\n",
    "\n",
    "    messages = state['messages']\n",
    "\n",
    "    user_cita = user_dia + \" de \" + user_mes + \" del 2024 a las \" + user_hora + \" horas\"\n",
    "    agenda_local = collection.find({'cita': user_cita})\n",
    "    repetidas = []\n",
    "\n",
    "    for agenda_citas in agenda_local:\n",
    "        repetidas.append(agenda_citas)\n",
    "    if len(repetidas)>0:\n",
    "        print(\"agenda otra hora\")\n",
    "    else:\n",
    "        print(\"añadir cita\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86fa43bb-8419-4cfe-bd42-0bf7626376b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1 = Ollama(model='llama3', temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e7f008-4fb4-40ab-aed1-3635e9d35cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Cuanto es 1 + 1?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6543966-780e-4521-a496-bfb0fe3ca316",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = MessageGraph()\n",
    "\n",
    "graph.add_node(\"oracle\", llm1)\n",
    "graph.add_edge(\"oracle\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cbbe01e-0b80-49ef-8a1a-78704bb47834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese mensaje:  hola\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=['hola'], id='66d7060f-5fe6-4128-89db-34718fc4324c'), HumanMessage(content='Spanish! \"Hola\" is a common greeting in Spanish, which means \"hello\".', id='e7a8a99f-611b-4983-91d8-8feb591a8a46')]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese mensaje:  tienes memoria?\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for HumanMessage\ncontent\n  str type expected (type=type_error.str)\ncontent -> 1\n  str type expected (type=type_error.str)\ncontent -> 1\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIngrese mensaje: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m AgentState1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(user_input)\n\u001b[1;32m----> 9\u001b[0m respuesta \u001b[38;5;241m=\u001b[39m runnable\u001b[38;5;241m.\u001b[39minvoke(HumanMessage(AgentState1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     10\u001b[0m AgentState1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(respuesta)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(respuesta)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LangChain_Intento9_OllamaFull\\Lib\\site-packages\\langchain_core\\messages\\base.py:47\u001b[0m, in \u001b[0;36mBaseMessage.__init__\u001b[1;34m(self, content, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m, content: Union[\u001b[38;5;28mstr\u001b[39m, List[Union[\u001b[38;5;28mstr\u001b[39m, Dict]]], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m     45\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Pass in content as positional arg.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(content\u001b[38;5;241m=\u001b[39mcontent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LangChain_Intento9_OllamaFull\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for HumanMessage\ncontent\n  str type expected (type=type_error.str)\ncontent -> 1\n  str type expected (type=type_error.str)\ncontent -> 1\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "terminar = \"bye\"\n",
    "user_input = \"\"\n",
    "\n",
    "while user_input != terminar:\n",
    "    user_input = input(\"Ingrese mensaje: \")\n",
    "    respuesta = runnable.invoke(HumanMessage(user_input))\n",
    "    print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ffdbbf-0078-48e5-b873-c4cda771d213",
   "metadata": {},
   "source": [
    "## Conditional Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09110a0b-b297-46dc-a95c-e355f287cd44",
   "metadata": {},
   "source": [
    "# Paso 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c61d78-1856-4e44-a37e-731be1777a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asigna AgentState como un diccionario vacío\n",
    "AgentState = {}\n",
    "\n",
    "# La key de mensajes se asignará como un array vacío. Agregaremos nuevos mensajes a medida que pasemos por los nodos. \n",
    "AgentState[\"messages\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab2dcf-0879-45c7-aeaa-2c5f941f0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045e76b-df3e-4e58-a04d-3ea2232d09b7",
   "metadata": {},
   "source": [
    "##### Nuestro objetivo es que este estado se llene así: {'messages': [HumanMessage, AIMessage, ...]]}\r\n",
    "Además, ahora necesitamos modificar nuestras funciones para pasar información a lo largo del nuevo AgentState.te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e28b76-94de-4020-bd01-60fbbacb5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(state): #buscar usuario\n",
    "    messages = state['messages']\n",
    "    user_input = messages[-1]\n",
    "    documents = str({\n",
    "  \"nombre\": \"Osvaldo\",\n",
    "  \"correo\": \"osvaldo@email.com\",\n",
    "  \"citacion\": \"miércoles 22 de mayo a las 15:00\",\n",
    "  \"telefono\": \"\"\n",
    "})\n",
    "    complete_query = \"Dime los siguientes datos obtenidos desde una base de datos:\" + documents\n",
    "    respuesta = llm1.invoke(complete_query)\n",
    "    print(respuesta)\n",
    "    print(respuesta[-1])\n",
    "    state['messages'].append(respuesta) # añadiendo la respuesta AIMessage al AgentState\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c5fae-2f35-47bb-838a-94f80c5e7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(state): #agendar cita\n",
    "\n",
    "    messages2 = state['messages']\n",
    "    datos_recibidos = messages2[-1]\n",
    "    query_nueva = \"Tienes los siguientes datos: \" + datos_recibidos + \", consulta por los faltantes, y si no faltan, pregunta si quiere agendar una cita nueva\"\n",
    "    respuesta_nueva = llm1.invoke(query_nueva)\n",
    "    print(respuesta_nueva)\n",
    "    print(respuesta_nueva[-1])\n",
    "    state['messages'].append(respuesta_nueva)\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef9e35-062b-436e-9284-ae5e10f0c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function3(state): \n",
    "    messages3 = state['messages']\n",
    "    datos_recibidos2 = messages3[-1]\n",
    "    query_nueva2 = \"Asume que la respuesta fue un sí y pregunta a qué hora la cita nueva\"\n",
    "    respuesta_nueva2 = llm1.invoke(query_nueva2)\n",
    "    print(respuesta_nueva2)\n",
    "    print(respuesta_nueva2[-1])\n",
    "    state['messages'].append(respuesta_nueva2)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1250c-4301-44ff-be68-53254ba61d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph\n",
    "\n",
    "workflow = Graph()\n",
    "\n",
    "\n",
    "workflow.add_node(\"agent\", function1)\n",
    "workflow.add_node(\"tool\", function2)\n",
    "workflow.add_node(\"responder\", function3)\n",
    "\n",
    "workflow.add_edge('agent', 'tool')\n",
    "workflow.add_edge('tool', 'responder')\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"responder\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fae9b1-80cd-4f4f-bf27-4f084f0e1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [\"what is the temperature in las vegas\"]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346ca5d-b0d5-41fb-9337-677ab5a9812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"messages\": [\"Quiero una cita, me llamo Osvaldo\"]}\n",
    "for output in app.stream(input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac3667-9f1e-4942-b744-e50b0f4429e8",
   "metadata": {},
   "source": [
    "Como notamos que se están agregando muchas cosas al array, podemos hacerlo un poco más fácil con lo siguiente:\r\n",
    "\r\n",
    "```bash\r\n",
    "from typing import TypedDict, Annotated, Sequence\r\n",
    "import operator\r\n",
    "from langchain_core.messages import BaseMessage\r\n",
    "\r\n",
    "\r\n",
    "class AgentState(TypedDict):\r\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]seMessage], operator.add]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ff1c3-1567-48fc-957b-cb69334603db",
   "metadata": {},
   "source": [
    "# Conditonal Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f858806f-90b7-4fe0-9fa4-670efb5a3bd8",
   "metadata": {},
   "source": [
    "Podemos hacer que nuestro agente sea más inteligente diciéndole que solo use la herramienta cuando sea necesario, si no simplemente responda al usuario. \n",
    "\n",
    "La forma en que podemos hacer este LangGraph es:\n",
    "1. Vincular una Tool al agente\n",
    "2. Añadirr unaConditional Edgel al agente con la opción de llamar a laTool  o n\n",
    "3. definiendo los criterios para el Conditional Edge sobre cuándo llamar a la Tool. Definiremos una función para esto..\n",
    "\n",
    "Comencemos con la definición de AgentState como se menciona algunas celdas arriba.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849997dd-4820-4d92-8af8-fd16711ffafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197cdbe-6fe2-44af-bddf-ee89e06e3aab",
   "metadata": {},
   "source": [
    "La herramienta de vinculación con agente (modelo LLM) se simplifica en langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16aaf72-a345-40da-a85a-d06ecf53e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "model = Ollama(temperature=0, model='llama3')\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d569289-5394-43a1-90b9-98c3a0006c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool\n",
    "def multiply(first_number: int, second_number: int):\n",
    "    \"\"\"Multiplies two numbers together.\"\"\"\n",
    "    return first_number * second_number\n",
    "\n",
    "model = Ollama(model='llama3',temperature=0)\n",
    "model_with_tools = model.bind_tools([multiply])\n",
    "\n",
    "builder = MessageGraph()\n",
    "\n",
    "builder.add_node(\"oracle\", model_with_tools)\n",
    "\n",
    "tool_node = ToolNode([multiply])\n",
    "builder.add_node(\"multiply\", tool_node)\n",
    "\n",
    "builder.add_edge(\"multiply\", END)\n",
    "\n",
    "builder.set_entry_point(\"oracle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ebb129-67e4-480e-b24a-c0f91903fc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
