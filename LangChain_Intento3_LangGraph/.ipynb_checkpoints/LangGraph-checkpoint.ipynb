{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "710c86db-74c5-4b73-9776-4ed891ea9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langgraph -q\n",
    "!pip install langchain -q\n",
    "!pip install ollama -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d93f56-c76c-430d-93e4-759a541e5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547855e3-809c-4c8e-898c-7c69f644c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ollama(model=\"llama3\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2c962a-f2c8-4c5c-b526-17c6e69a1601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey! How's it going?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('Hey there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4192ac6-88f8-459d-ad8b-e1f29719e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = MessageGraph()\n",
    "\n",
    "graph.add_node(\"oracle\", model)\n",
    "graph.add_edge(\"oracle\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7119cf9-d5bd-4ca2-a974-02c8d78e2551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 1 + 1?', id='c8b9b928-9f01-4c1b-9a77-3950752593e7'),\n",
       " HumanMessage(content='Easy one!\\n\\nThe answer is... 2!', id='119fc37c-df3a-45bd-8051-450e28e5af21')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke(HumanMessage(\"What is 1 + 1?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebea88e-0e9c-4c15-9fd2-7c5eb55a7006",
   "metadata": {},
   "source": [
    "# Connect with HuggingFace via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d0207e2-880e-4f1f-ae93-4b2bf68f6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub python_dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af6d4b8-a74c-4abe-8bb1-6d94130a9276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1efc319e-e91b-44cd-a398-931ddec5ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'HUGGINGFACEHUB_API_TOKEN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090d100-8f59-45a5-90cd-6ffa37f0e32f",
   "metadata": {},
   "source": [
    "## con LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7bd57fa-2e27-404c-b262-9bc0df441f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "\n",
    "plantilla = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=plantilla, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf460bcc-481b-4d12-bb6e-25c6eba999e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "GatedRepoError",
     "evalue": "401 Client Error. (Request ID: Root=1-6648e271-506fe6730fa7566343ccd69a;349b46b8-3722-468a-8aea-e90293ce9661)\n\nCannot access gated repo for url https://huggingface.co/api/models/meta-llama/Meta-Llama-3-8B.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must be authenticated to access it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/meta-llama/Meta-Llama-3-8B",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m----> 2\u001b[0m                      llm\u001b[38;5;241m=\u001b[39mHuggingFaceHub(repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m                                         model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m128\u001b[39m}))\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:183\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     emit_warning()\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\pydantic\\v1\\main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m validator(cls_, values)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\langchain_community\\llms\\huggingface_hub.py:80\u001b[0m, in \u001b[0;36mHuggingFaceHub.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify either `repo_id` or `task`, or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m         )\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# Use the recommended task for the chosen model\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     model_info \u001b[38;5;241m=\u001b[39m HfApi(token\u001b[38;5;241m=\u001b[39mhuggingfacehub_api_token)\u001b[38;5;241m.\u001b[39mmodel_info(\n\u001b[0;32m     81\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id\n\u001b[0;32m     82\u001b[0m     )\n\u001b[0;32m     83\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model_info\u001b[38;5;241m.\u001b[39mpipeline_tag\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m VALID_TASKS_DICT:\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\huggingface_hub\\hf_api.py:2301\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[1;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[0;32m   2299\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2300\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m-> 2301\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   2302\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain_Intento3_LangGraph\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:321\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    318\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    324\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    330\u001b[0m     )\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-6648e271-506fe6730fa7566343ccd69a;349b46b8-3722-468a-8aea-e90293ce9661)\n\nCannot access gated repo for url https://huggingface.co/api/models/meta-llama/Meta-Llama-3-8B.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must be authenticated to access it."
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt,\n",
    "                     llm=HuggingFaceHub(repo_id=\"meta-llama/Meta-Llama-3-8B\",\n",
    "                                        model_kwargs={\"temperature\":0,\n",
    "                                                      \"max_length\":128}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5317e-4dd9-4a81-8a4c-1b478aae9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the capital of Spain?\"\n",
    "\n",
    "print(llm_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f45dd6-2bfc-4b51-bd83-ebf2b365c49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873858b-ad12-429f-a42d-444e98039390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e0799-7de6-496f-9fdc-e4a907e529db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_api = InferenceClient(\n",
    "    model = 'google/flan-t5-large',\n",
    "    token = os.environ['HUGGINGFACEHUB_API_TOKEN']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ac76c6-16da-4999-b9fa-0781df144a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pregunta = 'Cuál es la capital de Chile?'\n",
    "\n",
    "prompt = f\"\"\"Question: {pregunta}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d335511a-e356-491b-9204-27945466a93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Cuál es la capital de Chile?\n",
      "\n",
      "Answer: Let's think step by step.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a3a9032-efb1-4b30-a3a8-e8ab41bac143",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'InferenceClient' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_api(prompt)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'InferenceClient' object is not callable"
     ]
    }
   ],
   "source": [
    "model_api(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d63f24-056d-4475-943c-aad8f41a773b",
   "metadata": {},
   "source": [
    "# Conditional Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8026bd-7e9a-40a9-8b67-2756d56cf37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e1b4f-8881-4901-94eb-31491971b3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
